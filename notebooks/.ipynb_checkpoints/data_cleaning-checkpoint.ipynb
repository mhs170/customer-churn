{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# df = pd.read_csv('/Users/mohammed/Downloads/used-cars-sales-prediction/data/raw.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_missing_data(df):\n",
    "    missing_summary = df.isnull().sum()\n",
    "    missing_percentage = (missing_summary / len(df)) * 100\n",
    "    missing_report = pd.DataFrame({\n",
    "        'Missing Count': missing_summary,\n",
    "        'Missing Percentage': missing_percentage\n",
    "    })\n",
    "    print(\"Missing Data Report:\")\n",
    "    print(missing_report)\n",
    "    return missing_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, columns):\n",
    "    for col in columns:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_rows(df):\n",
    "    duplicate_mask = df.duplicated(keep=False)\n",
    "    duplicate_rows = df[duplicate_mask]\n",
    "    return duplicate_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(df):\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"Number of duplicates before dropping: {duplicate_count}\")\n",
    "    df = df.drop_duplicates()\n",
    "    return df, duplicate_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove $ from price column to convert to numerical data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price_column(df, column_name=\"price\"):\n",
    "    df[column_name] = (\n",
    "        df[column_name]\n",
    "        .str.replace('$', '', regex=False)  # Remove dollar sign\n",
    "        .str.replace(',', '', regex=False)  # Remove commas\n",
    "        .astype(float)  # Convert to float\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column_name, threshold=3):\n",
    "    df['z_score'] = zscore(df[column_name])\n",
    "    original_row_count = len(df)\n",
    "    df_cleaned = df[df['z_score'].abs() <= threshold]\n",
    "    cleaned_row_count = len(df_cleaned)\n",
    "    rows_affected = original_row_count - cleaned_row_count\n",
    "    df_cleaned = df_cleaned.drop(columns=['z_score'])\n",
    "    print(f\"Number of rows affected by removing outliers: {rows_affected}\")\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for outliers in model_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_year(df, column_name):\n",
    "    earliest_year = df[column_name].min()\n",
    "    latest_year = df[column_name].max()\n",
    "    print(f\"Earliest Year: {earliest_year}\")\n",
    "    print(f\"Latest Year: {latest_year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)  # Ensure the directory exists\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data Report:\n",
      "              Missing Count  Missing Percentage\n",
      "brand                     0            0.000000\n",
      "model                     0            0.000000\n",
      "model_year                0            0.000000\n",
      "milage                    0            0.000000\n",
      "fuel_type                 0            0.000000\n",
      "engine                    0            0.000000\n",
      "transmission              0            0.000000\n",
      "ext_col                   0            0.000000\n",
      "int_col                   0            0.000000\n",
      "accident                113            2.818658\n",
      "clean_title             596           14.866550\n",
      "price                     0            0.000000\n",
      "Duplicate rows found:\n",
      "Empty DataFrame\n",
      "Columns: [brand, model, model_year, milage, fuel_type, engine, transmission, ext_col, int_col, accident, clean_title, price]\n",
      "Index: []\n",
      "Number of duplicates before dropping: 0\n",
      "Number of duplicates removed: 0\n",
      "Number of rows affected by removing outliers: 31\n",
      "Earliest Year: 1974\n",
      "Latest Year: 2024\n",
      "Cleaned data saved to /Users/mohammed/Downloads/used-cars-sales-prediction/notebooks/../data/cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "project_root = os.getcwd()  # Get the directory of this script\n",
    "raw_data_path = os.path.join(project_root, \"../data/raw.csv\")\n",
    "cleaned_data_path = os.path.join(project_root, \"../data/cleaned.csv\")\n",
    "\n",
    "# Load raw data\n",
    "raw_data = load_data(raw_data_path)\n",
    "\n",
    "missing_report = identify_missing_data(raw_data)\n",
    "\n",
    "columns_to_fill = ['fuel_type', 'accidents', 'clean_title']\n",
    "raw_data = fill_missing_values(df, columns_to_fill)\n",
    "\n",
    "duplicate_rows = find_duplicate_rows(raw_data)\n",
    "print(\"Duplicate rows found:\")\n",
    "print(duplicate_rows)\n",
    "\n",
    "raw_data, duplicate_count = drop_duplicates(raw_data)\n",
    "print(f\"Number of duplicates removed: {duplicate_count}\")\n",
    "\n",
    "raw_data = clean_price_column(raw_data)\n",
    "\n",
    "raw_data = remove_outliers(raw_data, 'price')\n",
    "\n",
    "find_year(raw_data, 'model_year')\n",
    "\n",
    "save_data(raw_data, cleaned_data_path)\n",
    "print(f\"Cleaned data saved to {cleaned_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
